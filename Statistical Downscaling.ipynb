{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Downscaling Model (Machine learning methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Main Functions\n",
    "import datetime as dt # Work with datetime format\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc # Work with NetCDF format files\n",
    "import numpy as np # Array processing for numbers, strings, records, and objects\n",
    "import os # use OS functions\n",
    "import pandas as pd # Work with Pandas DataFrames\n",
    "import warnings # manage warning alerts\n",
    "import sys\n",
    "sys.path.append('G:\\\\Mi unidad\\\\PhD\\\\Research\\\\Machine Learning for Downscaling Comparison\\\\Scripts\\\\Machine Learning Models\\\\')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing auxiliar functions\n",
    "from DSMethods import multi_layer_perceptron # Import Linear regression Functions\n",
    "from DSMethods import k_Nearest_Neighbors # Import k-NN Functions\n",
    "from DSMethods import linear_regression # Import Linear regression Functions\n",
    "from DSMethods import forest_trees # Import Forest Tree Decision Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main variables\n",
    "station_data=\"fill\" # csv file with the climatic data of the stations\n",
    "station_catalog=\"fill\" # csv file with latitude and longitude of the stations\n",
    "model_historic=\"fill\" # folder with the nc files with the historic experiment of the GCM\n",
    "model_rcp=\"fill\" # folder with the nc files with the RCP experiment of the GCM\n",
    "output_folder=\"fill\" # folder to save the results and plots\n",
    "cal_date=\"fill\" # last date of the calibration process\n",
    "val_date=\"fill\" # val_date: last date of the validation process\n",
    "app_date=\"fill\" # app_date: last date of the application process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The code works for daily values only right now\n",
    "station=pd.read_csv(station_data)\n",
    "dateparse = lambda x: pd.datetime.strptime(x,'%d/%m/%Y')\n",
    "station=pd.read_csv(station_data,index_col='Date',parse_dates=True, date_parser=dateparse)\n",
    "catalogo=pd.read_csv(station_catalog)\n",
    "if any(catalogo['Longitud']<0):\n",
    "    catalogo['Longitud']=catalogo['Longitud']+360\n",
    "ns=station.shape[1]\n",
    "print(\"Loading NetCDF Data: Historic Data \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time model data\n",
    "time_his=[];time_rcp=[];    \n",
    "for filename in os.listdir(model_historic):\n",
    "    his = nc.Dataset(model_historic+filename)\n",
    "    if filename==os.listdir(model_historic)[0]:\n",
    "        time_unit=his.variables['time'].units \n",
    "        time_cal=his.variables['time'].calendar\n",
    "    time_valh=his.variables['time'][:] -0.5 \n",
    "    time_his=np.concatenate((time_his,nc.num2date(time_valh,units=time_unit,calendar=time_cal)))    \n",
    "if time_his[0].year>=1900:\n",
    "    time_his=[dt.datetime.strptime(k.strftime('%Y-%m-%d'),'%Y-%m-%d') for k in time_his]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid model data\n",
    "gcm_lat=his.variables['lat'][:]\n",
    "gcm_lon=his.variables['lon'][:]\n",
    "if  (gcm_lon<0).any():\n",
    "    gcm_lon=gcm_lon+360   \n",
    "if len(gcm_lat.shape)==1:\n",
    "    gcm_lat=np.array([gcm_lat,]* len(gcm_lon)).transpose()\n",
    "    gcm_lon=np.array([gcm_lon,]* len(gcm_lat))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units Conversion\n",
    "var_type=his.variables.keys()[-1]\n",
    "if var_type=='pr':\n",
    "    factor1=86400 # Conversion from kg/m^2/s to mm/day \n",
    "    factor2=0\n",
    "    # units='(mm)'\n",
    "else: # Temperature: tas, tas_min, tas_max\n",
    "    factor1=1\n",
    "    factor2=-273.15 # Conversion from °K to ° C\n",
    "    # units='(C)'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading NetCDF Data: RCP Data \")\n",
    "for filename in os.listdir(model_rcp):\n",
    "    rcp = nc.Dataset(model_rcp+filename)  \n",
    "    if filename==os.listdir(model_rcp)[0]:\n",
    "        rcp_model=rcp.model_id\n",
    "        rcp_esc=rcp.experiment_id\n",
    "        time_unit1=rcp.variables['time'].units \n",
    "        time_cal1=rcp.variables['time'].calendar\n",
    "    rcp = nc.Dataset(model_rcp+filename)\n",
    "    time_valf=rcp.variables['time'][:]-0.5\n",
    "    time_rcp=np.concatenate((time_rcp,nc.num2date(time_valf,units=time_unit1,calendar=time_cal1)))\n",
    "time_rcp=[dt.datetime.strptime(k.strftime('%Y-%m-%d'),'%Y-%m-%d') for k in time_rcp]\n",
    "time_gcm=np.concatenate((time_his, time_rcp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Get GCM cell and model information\")\n",
    "gcm_cell=np.empty((ns,3))* np.nan \n",
    "model=[None]*(ns-1)\n",
    "n=0\n",
    "start=station.index[0]\n",
    "knn_future=pd.DataFrame(index=pd.date_range(start,app_date))\n",
    "for_future=pd.DataFrame(index=pd.date_range(start,app_date))\n",
    "lin_future=pd.DataFrame(index=pd.date_range(start,app_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in catalogo.index:\n",
    "    print(\"Station \"+str(z+1) +\": \" +str(catalogo['ID'][z]))\n",
    "    for cell_x in range(int(gcm_lat.shape[0])-1):\n",
    "        for cell_y in range(int(gcm_lat.shape[1])-1):\n",
    "            if (gcm_lat[cell_x-1,cell_y-1]+gcm_lat[cell_x,cell_y-1])/2<=catalogo['Latitud'][z] and catalogo['Latitud'][z]<=(gcm_lat[cell_x+1,cell_y-1]+gcm_lat[cell_x,cell_y-1])/2:    \n",
    "                if (gcm_lon[cell_x-1,cell_y-1]+gcm_lon[cell_x-1,cell_y])/2<=catalogo['Longitud'][z] and catalogo['Longitud'][z]<=(gcm_lon[cell_x-1,cell_y+1]+gcm_lon[cell_x-1,cell_y])/2:                   \n",
    "                    gcm_cell[z,0]= cell_x    \n",
    "                    gcm_cell[z,1]= cell_y\n",
    "                cell_y=cell_y+1\n",
    "        cell_x=cell_x+1\n",
    "    if any((np.array([int(gcm_cell[z,0]),int(gcm_cell[z,1])])== x).all() for x in np.delete(gcm_cell,z,0)[:,:2]):       \n",
    "        cell_pos=np.where((gcm_cell[:,0:2]==[int(gcm_cell[z,0]),int(gcm_cell[z,1])]).all(axis=1))      \n",
    "        gcm_cell[z,2]=gcm_cell[cell_pos[0][0],2]\n",
    "    else:         \n",
    "        data_his=[];data_rcp=[];\n",
    "        for filename in os.listdir(model_historic):\n",
    "            his = nc.Dataset(model_historic+'\\\\'+filename)    \n",
    "            data_his=np.concatenate((data_his,his.variables[var_type][:,int(gcm_cell[z,0]),int(gcm_cell[z,1])]*factor1+factor2))    \n",
    "        for filename in os.listdir(model_rcp):\n",
    "            rcp = nc.Dataset(model_rcp+'\\\\'+filename)      \n",
    "            data_rcp=np.concatenate((data_rcp,rcp.variables[var_type][:,int(gcm_cell[z,0]),int(gcm_cell[z,1])]*factor1+factor2))    \n",
    "        model[n]=np.concatenate((data_his, data_rcp))\n",
    "        gcm_cell[z,2]=n\n",
    "        n=n+1\n",
    "    his.close\n",
    "    rcp.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in catalogo.index:\n",
    "    # Relacionando datos para cada estación\n",
    "    estacion=station[str(catalogo['ID'][z])]\n",
    "    estacion=estacion.dropna()\n",
    "    gcm=pd.DataFrame(model[int(gcm_cell[z,2])],index=time_gcm,columns=['GCM']) \n",
    "    # K-Nearest Neighbors\n",
    "    print(\"    k-NN\")\n",
    "    knn_future[str(catalogo['ID'][z])]=k_Nearest_Neighbors.K_NN(estacion,gcm,cal_date,app_date)\n",
    "    data_anually=knn_future[str(catalogo['ID'][z])].resample('A', how='sum')\n",
    "    data_anually.plot()\n",
    "    plt.savefig(output_folder+str(catalogo['ID'][z])+'_'+'knn'+'_'+rcp_model+'_'+var_type+'_'+rcp_esc+'.png')\n",
    "\n",
    "    # Random Forest\n",
    "    print(\"    Forest\")\n",
    "    for_future[str(catalogo['ID'][z])]=forest_trees.Decision_tree(estacion,gcm,cal_date,app_date)\n",
    "    data_anually=for_future[str(catalogo['ID'][z])].resample('A', how='sum')\n",
    "    data_anually.plot()\n",
    "    plt.savefig(output_folder+str(catalogo['ID'][z])+'_'+'forest'+'_'+rcp_model+'_'+var_type+'_'+rcp_esc+'.png')\n",
    "\n",
    "    # Linear regression\n",
    "    print(\"    Linear\")\n",
    "    lin_future[str(catalogo['ID'][z])]=linear_regression.Lin_regr(estacion,gcm,cal_date,app_date)\n",
    "    data_anually=lin_future[str(catalogo['ID'][z])].resample('A', how='sum')\n",
    "    data_anually.plot()\n",
    "    plt.savefig(output_folder+str(catalogo['ID'][z])+'_'+'forest'+'_'+rcp_model+'_'+var_type+'_'+rcp_esc+'.png')    \n",
    "\n",
    "    # Multi Layer Perceptron (MLP)   \n",
    "    print(\"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_future.to_csv(output_folder+'knn'+'_'+rcp_model+'_'+var_type+'_'+rcp_esc+'.csv',index_label='Index')\n",
    "for_future.to_csv(output_folder+'forest'+'_'+rcp_model+'_'+var_type+'_'+rcp_esc+'.csv',index_label='Index')\n",
    "lin_future.to_csv(output_folder+'linear'+'_'+rcp_model+'_'+var_type+'_'+rcp_esc+'.csv',index_label='Index')\n",
    "#ann_future"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce4eb4d920092f806f03460c9e7d88ecde9146a0b4898dee9c2abea10a26caee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('oz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
